%% Module 2 beamer/knitr slides
%% Biostatistics in Practice workshop, January 2014
%% Nicholas Reich: nick [at] schoolph.umass.edu


\documentclass[table]{beamer}


\input{../../slide-includes/standard-knitr-beamer-preamble}

%        The following variables are assumed by the standard preamble:
%	Global variable containing module name:
\title{Longitudinal Data Analysis}
%	Global variable containing module shortname:
%		(Currently unused, may be used in future.)
\newcommand{\ModuleShortname}{LDA}
%	Global variable containing author name:
\author{Nicholas G Reich, Jeff Goldsmith }
%	Global variable containing text of license terms:
\newcommand{\LicenseText}{Made available under the Creative Commons Attribution-ShareAlike 3.0 Unported License: http://creativecommons.org/licenses/by-sa/3.0/deed.en\_US }
%	Instructor: optional, can leave blank.
%		Recommended format: {Instructor: Jane Doe}
\newcommand{\Instructor}{}
%	Course: optional, can leave blank.
%		Recommended format: {Course: Biostatistics 101}
\newcommand{\Course}{}

\input{../../slide-includes/shortcuts}
\usepackage{bbm}
\hypersetup{colorlinks=TRUE, urlcolor=blue}

%%%%%%%% IMPORTANT -- MUST HAVE [fragile] for some/all frames chunks to have output work correctly. 

\begin{document}

<<setup, include=FALSE>>=
library(knitr)
library(ggplot2)
opts_chunk$set(fig.path='figure/beamer-',fig.align='center',fig.show='hold',size='scriptsize')
@


\begin{frame}[plain]
        \titlepage
\end{frame}

<<ggplot2, echo=FALSE, message=FALSE>>=
require(ggplot2)
theme_set(theme_bw())
@

\begin{frame}{Focus on covariance}

\bi
        \myitem We've extensively used OLS for the model
		$$ \by = \bX \bbeta + \bepsilon$$ 
	where $E(\bepsilon) = 0$ and $Var(\bepsilon) = \sigma^2 I$
	\myitem We are now more interested in the case of $Var(\bepsilon) = \sigma^2 V$
\ei

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Longitudinal data}

\bi
	\myitem Data is gathered at multiple time points for each study participant
	\myitem Repeated observations / responses
	\myitem Longitudinal data regularly violates the ``independent errors" assumption of OLS
	\myitem LDA allows the examination of changes over time (aging effects) and adjustment for individual differences (subject effects)
\ei

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Some hypothetical data}

\begin{figure}[h]
    \includegraphics[width=\textwidth]{Fig01.png}  
\end{figure}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Notation}

\bi
	\myitem We observe data $y_{ij}, \bx_{ij}$ for subjects $i = 1, \ldots I$ at visits $j = 1, \ldots, J_i$
	\myitem Vectors $\by_{i}$ and matrices $\bX_{i}$ are subject-specific outcomes and design matrices
	\myitem Total number of visits is $n = \sum_{i = 1}^{I} J_i$
	\myitem For subjects $i$, let
		$$ \by_{i} = \bX_{i} \bbeta + \bepsilon_{i}$$
	where $\var(\bepsilon_{i}) = \sigma^2 V_{i}$
\ei

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Notation}

\bi
	\myitem Overall, we pose the model 
		$$ \by = \bX \bbeta + \bepsilon$$
	where $\var(\bepsilon) = \sigma^2 V$ and 
		$$ V = \left[ \begin{array}{cccc}
			V_1 		& 0 		& \ldots 	& 0 \\
			0 		& V_2	& \ldots 	& 0 \\
			\vdots 	& \vdots	& \ddots 	&  \\
			0 		& 0 		& 		& V_{I} \\
		 \end{array} \right]
		 $$
\ei


\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Covariates}

The covariates $\bx_{i} = x_{ij1} \ldots x_{ijp}$ can be
\bi
	\myitem Fixed at the subject level -- for instance, sex, race, fixed treatment effects
	\myitem Time varying -- age, BMI, smoking status, treatment in a cross-over design
\ei
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Motivation}

Why bother with LDA?
\bi
	\myitem Correct inference
	\myitem More efficient estimation of shared effects
	\myitem Estimation of subject-level effects / correlation
	\myitem The ability to ``borrow strength" -- use both subject- and population-level information
  \myitem Repeated measures is a very common feature of real data!
\ei

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Example dataset}

An example dataset comes from the Multicenter AIDS Cohort Study ({\tt CD4.txt}).
\bi
  \myitem 283 HIV+ individuals
	\myitem Observation of CD4 cell count (a measure of disease progression)
	\myitem Between 1 and 14 observations per subject (1817 total observations)
\ei

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{CD4 dataset}

<<loadData, message=FALSE>>=
library(timereg)
data(cd4)
head(cd4, 15)
@
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{CD4 dataset}

<<plotData, tidy=FALSE, fig.height=4>>=
qplot(visit, cd4, data=cd4)
@
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{CD4 dataset}

<<spagPlot, tidy=FALSE, fig.height=4>>=
qplot(visit, cd4, data=cd4, geom=c("point", "line"), 
      group=id)
@
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{CD4 dataset}

<<spagPlot2, tidy=FALSE, fig.height=4>>=
qplot(visit, cd4, data=cd4, geom=c("point", "line"), 
      group=id, alpha=I(.2))
@
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{CD4 dataset}

<<spagPlot3, tidy=FALSE, fig.height=4>>=
ids <- unique(cd4$id)
cd4$highlight <- as.factor(cd4$id %in% ids[1:10])
qplot(visit, cd4, data=cd4, geom=c("point", "line"), 
      group=id, color=highlight, alpha=highlight) +
        theme(legend.position="none")
@
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Visualizing covariances}

Suppose the data consists of three subjects with four data points each. 
\bi
        \myitem In the model
		$$ \by_{i} = \bX_{i} \bbeta + \bepsilon_{i}$$
	where $\var(\bepsilon_{i}) = \sigma^2 V_{i}$, what are some forms for $V_{i}$?
\ei

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Approaches to LDA}

We'll consider two main approaches to LDA
\bi
        \myitem Marginal models, which focus on estimating the main effects and variance matrices but don't introduce subject effects
        \bi
                \myitem ``Simplest'' LDA model, just like cross-sectional data
                \myitem Requires new methods, like GEE, to control for variance structure 
                \myitem Arguably easier incorporation of different variance structures
        \ei
        \myitem Random effects models, which introduce random subject effects (i.e. effects coming from a distribution, rather than from a ``true" parametric model)
        \bi
                \myitem ``Intuitive'' model descriptions
                \myitem Explicit estimation of variance components
                \myitem Caveat: can change parameter interpretations
        \ei
\ei

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{First problem: exchangeable correlation}

Start with the model where
$$V_{i} = \left[ \begin{array}{cccc}
			1 		& \rho	& \ldots 	& \rho \\
			\rho		& 1		& \ldots 	& \rho \\
			\vdots 	& \vdots	& \ddots 	&  \\
			\rho		& \rho	& 		& 1 \\
		 \end{array} \right]
$$
This implies 
\bi
	\myitem $var(y_{ij}) = \sigma^2$
	\myitem $cov(y_{ij}, y_{ij`})= \sigma^2 \rho$
	\myitem $cor(y_{ij},  y_{ij`})= \rho$
\ei

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Marginal model}

The marginal model is
        $$ \by = \bX \bbeta + \bepsilon$$
where 
\bi
	\myitem $\var(\bepsilon) = \sigma^2 V$, 
	\myitem $$V_{i} = \left[ \begin{array}{cccc}
			1 		& \rho	& \ldots 	& \rho \\
			\rho		& 1		& \ldots 	& \rho \\
			\vdots 	& \vdots	& \ddots 	&  \\
			\rho		& \rho	& 		& 1 \\
		 \end{array} \right]
	$$
\ei

Tricky part is estimating the variance of the parameter estimates for this new model.

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Fitting a marginal model using GEE}

Generalized Estimating Equations provide a semi-parametric method for fitting a marginal model that takes into account the correlation between observations.

$$ \mathbb E[CD4_{ij}|month] = \beta_0 + \beta_1 \cdot month $$

With GEE, assume  $V_{i}$ is exchangeable.

\scriptsize
<<MM, message=FALSE, results='hide', tidy=FALSE>>=
library(geepack)
linmod <- lm(cd4~visit, data=cd4)
geemod <- geeglm(cd4~visit, data=cd4, id=id, 
                 corstr="exchangeable")
@


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Fitting a marginal model using GEE}

$$ \mathbb E[CD4_{ij}|month] = \beta_0 + \beta_1 \cdot month $$

With GEE, assume $V_{i}$ is exchangeable.

\scriptsize
<<mmoutput>>=
summary(linmod)$coef
summary(geemod)$coef
@


\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Looking at the correlation structures: exchangeable}

\scriptsize
<<mmoutput1>>=
summary(geemod)
@

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Looking at the correlation structures: AR(1)}

\tiny
<<mmoutput2>>=
geemod1 <- geeglm(cd4~visit, data=cd4, id=id, 
                  corstr="ar1")
summary(geemod1)
@

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Comparing different GEE models}

\begin{block}{Not a straight-forward way to compare different correlation structures}
\bi
  \myitem Some work on AIC in the context of GEEs (\href{http://www.jstor.org/stable/2676849}{Pan, 2001})
  \myitem Not implemented in standard GEE packages
  \myitem In practice, knowledge of data structure guides choice.
\ei
\end{block}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Marginal model}

The marginal model formulation is
$$ \by = \bX \bbeta + \bepsilon$$
where
\bi
	\myitem $\bepsilon \sim \N{0}{\sigma^2 V}$
\ei

This approach focuses on the {\em marginal} distribution of $\by$, rather than on a subject-level {\em conditional} distribution.

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Can use Generalized Least Squares}

Given the model
	$$ \by = \bX \bbeta + \bepsilon$$ 
where $\bepsilon \sim N(0, \sigma^2 V)$ with $V$ known, we are essentially assuming
	$$ \by \sim N(\bX \bbeta, \sigma^2 V)$$
Using MLE, we find that
$\hat{\bbeta}_{GLS} = (\bX^{T}V^{-1} \bX)^{-1}\bX^{T} V^{-1}\by$
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Estimation -- marginal model}

\bi
	\myitem If we can use MLE when $V$ is known, maybe we can use MLE to estimate $V$ as well
	\myitem Our log likelihood function is
	\beqa
		l(\bbeta, \sigma^2, V; \by, \bX)  & = & -\frac{1}{2}\left[ n \log(\sigma^2) + \log(|V|) \right.\\
		&&\left. + \frac{1}{\sigma^2} ( \by - \bX \bbeta)^{T} V^{-1} ( \by - \bX \bbeta)\right]
	\eeqa
	\myitem Using profile likelihood, we find that for any $V_0$
		$$\hat{\bbeta}(V_0)= (\bX^{T} V_0^{-1} \bX)^{-1}\bX^{T} V_0^{-1}\by$$
\ei

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Estimation -- marginal model}

\bi
	\myitem Estimation of $V$ and $\sigma$ is done through restricted maximum likelihood
	\bi
		\item Standard MLE produces biased variance estimates; REML adjusts for the number of fixed effects components that are estimated
	\ei
	\myitem Often $V$ is structured parametrically to ease estimation and computation
	\myitem We won't worry about how this is done
\ei

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Random effects model}

A random intercept model with one covariate is given by 
$$ y_{ij} = \beta_{0} + b_{i} + \beta_{1} x_{ij} + \epsilon_{ij}$$
where
\bi
        \myitem $b_{i} \sim \N{0}{\tau^2}$
	\myitem $\epsilon_{ij} \sim \N{0}{\nu^2}$
\ei

{\bf For exchangeable correlation and continuous outcomes}, the random intercept model is equivalent to the marginal model.

Under this model
\bi
	\myitem $var(y_{ij}) = $
	\myitem $cov(y_{ij}, y_{ij`}) = $
	\myitem $cor(y_{ij},  y_{ij`}) = \rho = $
\ei


\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Fitting a random effects model}

\scriptsize
<<REmod, message=FALSE, warning=FALSE>>=
library(lme4)
memod <- lmer(cd4 ~ (1 | id) + visit, data = cd4)
summary(memod)$coef
summary(geemod)$coef
@

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Conclusion}

Today we have..
\bi

        \myitem introduced longitudinal data analysis.
        \myitem defined and fitted Marginal and Random Effects models.

\ei


\end{frame}

\end{document}
